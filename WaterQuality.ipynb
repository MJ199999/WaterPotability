{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ199999/WaterPotability/blob/main/WaterQuality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZP8ace0eXmw"
      },
      "outputs": [],
      "source": [
        "!pip install dataprep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZqooS6xXY4Fm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "PEt-icHXbPSE"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"water_potability.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZBfc9ZxBbZUA",
        "outputId": "c4df6ba1-fa1b-4da7-9dd7-68491b7c3d2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f329c1a-d229-4acb-a73b-db5dab4862b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f329c1a-d229-4acb-a73b-db5dab4862b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f329c1a-d229-4acb-a73b-db5dab4862b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f329c1a-d229-4acb-a73b-db5dab4862b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
              "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
              "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM70ZAhVbbeB",
        "outputId": "71cd4dbb-1a36-4489-8be0-32aeba99afd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wTC2YRJrbxRL"
      },
      "outputs": [],
      "source": [
        "data2 = data.dropna(axis=0)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data2.drop(['Potability'], axis=1)\n",
        "y = data2.Potability\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.1)\n",
        "train = pd.concat([train_X, train_y], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "train_potable = train[train['Potability']==1]\n",
        "train_notpotable = train[train['Potability']==0]\n",
        "df_minority_upsampled = resample(train_potable, replace=True, n_samples=1200)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "train_s = pd.concat([train_notpotable, df_minority_upsampled])\n",
        "train_s = shuffle(train_s)\n",
        "\n",
        "train_s_X = train_s.drop(['Potability'], axis=1)\n",
        "train_s_y =  train_s.Potability"
      ],
      "metadata": {
        "id": "g4Lh-q2LmLAx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "5DPHNpZ1nlHe",
        "outputId": "282ff2b5-4417-4ce0-a7c1-0dc99b4324f0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "42    7.145772  238.689929  28780.340432     6.814029  385.975650   \n",
              "3082  5.093675  251.313780  30245.956975     6.718830  267.026093   \n",
              "2304  7.116133  204.040782  25131.665279     5.402655  292.324403   \n",
              "2746  5.636924  159.139410  27283.780655     6.918727  328.907287   \n",
              "362   6.876451  190.844514  21979.031671     5.630558  363.831706   \n",
              "...        ...         ...           ...          ...         ...   \n",
              "1628  6.769769  178.331753  16980.258481     7.051697  369.906278   \n",
              "2774  7.288113  216.612475  18979.981692     7.668510  358.978620   \n",
              "1696  7.290089  205.213105  26115.616326     5.137891  357.794088   \n",
              "1238  6.582500  200.733107  23720.481730     8.565832  353.008115   \n",
              "2042  7.669013  205.595635  11579.441693     4.263279  356.136518   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "42      332.032706       11.093163        66.138045   5.182591           0  \n",
              "3082    271.630738       14.882428        70.778408   4.552571           0  \n",
              "2304    424.003499       12.836710        55.404587   3.915382           1  \n",
              "2746    317.830981       13.611408        36.335199   3.007138           1  \n",
              "362     349.186085        9.551732        68.410851   4.545341           1  \n",
              "...            ...             ...              ...        ...         ...  \n",
              "1628    299.404977       18.703657        62.868527   3.846612           1  \n",
              "2774    384.694955       14.163607        53.313046   3.626990           1  \n",
              "1696    402.874799        7.960478        63.698514   4.700618           0  \n",
              "1238    458.362733       13.001881        79.529338   4.152014           0  \n",
              "2042    407.721613       10.829045        83.243808   4.589513           1  \n",
              "\n",
              "[2276 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ea62361-75f8-48ce-a160-884b91cbbcb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>7.145772</td>\n",
              "      <td>238.689929</td>\n",
              "      <td>28780.340432</td>\n",
              "      <td>6.814029</td>\n",
              "      <td>385.975650</td>\n",
              "      <td>332.032706</td>\n",
              "      <td>11.093163</td>\n",
              "      <td>66.138045</td>\n",
              "      <td>5.182591</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3082</th>\n",
              "      <td>5.093675</td>\n",
              "      <td>251.313780</td>\n",
              "      <td>30245.956975</td>\n",
              "      <td>6.718830</td>\n",
              "      <td>267.026093</td>\n",
              "      <td>271.630738</td>\n",
              "      <td>14.882428</td>\n",
              "      <td>70.778408</td>\n",
              "      <td>4.552571</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2304</th>\n",
              "      <td>7.116133</td>\n",
              "      <td>204.040782</td>\n",
              "      <td>25131.665279</td>\n",
              "      <td>5.402655</td>\n",
              "      <td>292.324403</td>\n",
              "      <td>424.003499</td>\n",
              "      <td>12.836710</td>\n",
              "      <td>55.404587</td>\n",
              "      <td>3.915382</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2746</th>\n",
              "      <td>5.636924</td>\n",
              "      <td>159.139410</td>\n",
              "      <td>27283.780655</td>\n",
              "      <td>6.918727</td>\n",
              "      <td>328.907287</td>\n",
              "      <td>317.830981</td>\n",
              "      <td>13.611408</td>\n",
              "      <td>36.335199</td>\n",
              "      <td>3.007138</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>6.876451</td>\n",
              "      <td>190.844514</td>\n",
              "      <td>21979.031671</td>\n",
              "      <td>5.630558</td>\n",
              "      <td>363.831706</td>\n",
              "      <td>349.186085</td>\n",
              "      <td>9.551732</td>\n",
              "      <td>68.410851</td>\n",
              "      <td>4.545341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1628</th>\n",
              "      <td>6.769769</td>\n",
              "      <td>178.331753</td>\n",
              "      <td>16980.258481</td>\n",
              "      <td>7.051697</td>\n",
              "      <td>369.906278</td>\n",
              "      <td>299.404977</td>\n",
              "      <td>18.703657</td>\n",
              "      <td>62.868527</td>\n",
              "      <td>3.846612</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>7.288113</td>\n",
              "      <td>216.612475</td>\n",
              "      <td>18979.981692</td>\n",
              "      <td>7.668510</td>\n",
              "      <td>358.978620</td>\n",
              "      <td>384.694955</td>\n",
              "      <td>14.163607</td>\n",
              "      <td>53.313046</td>\n",
              "      <td>3.626990</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1696</th>\n",
              "      <td>7.290089</td>\n",
              "      <td>205.213105</td>\n",
              "      <td>26115.616326</td>\n",
              "      <td>5.137891</td>\n",
              "      <td>357.794088</td>\n",
              "      <td>402.874799</td>\n",
              "      <td>7.960478</td>\n",
              "      <td>63.698514</td>\n",
              "      <td>4.700618</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>6.582500</td>\n",
              "      <td>200.733107</td>\n",
              "      <td>23720.481730</td>\n",
              "      <td>8.565832</td>\n",
              "      <td>353.008115</td>\n",
              "      <td>458.362733</td>\n",
              "      <td>13.001881</td>\n",
              "      <td>79.529338</td>\n",
              "      <td>4.152014</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2042</th>\n",
              "      <td>7.669013</td>\n",
              "      <td>205.595635</td>\n",
              "      <td>11579.441693</td>\n",
              "      <td>4.263279</td>\n",
              "      <td>356.136518</td>\n",
              "      <td>407.721613</td>\n",
              "      <td>10.829045</td>\n",
              "      <td>83.243808</td>\n",
              "      <td>4.589513</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2276 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ea62361-75f8-48ce-a160-884b91cbbcb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ea62361-75f8-48ce-a160-884b91cbbcb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ea62361-75f8-48ce-a160-884b91cbbcb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSSTpSD7gE5o"
      },
      "outputs": [],
      "source": [
        "# from dataprep.eda import create_report\n",
        "# create_report(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "g2oSH3CjgFxU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "def scaler_samples(train_X,test_X):\n",
        "  scaler = StandardScaler()\n",
        "  train_X = scaler.fit_transform(train_X)\n",
        "  test_X = scaler.transform(test_X)\n",
        "\n",
        "  return train_X, test_X\n",
        "\n",
        "train_s_X, test_X = scaler_samples(train_s_X, test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2qOkVrPi9WD"
      },
      "source": [
        "* ## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWHey8eAh0MF",
        "outputId": "19a9dbec-5f4d-42db-919f-4e788f03972e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', n_estimators=20)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
        "clf.fit(train_s_X, train_s_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9wC4dhkiJR0",
        "outputId": "f3901856-0c96-4afd-f836-7de1aa031efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.70\n"
          ]
        }
      ],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy\n",
        "y_pred = clf.predict(test_X)\n",
        "print(\"accuracy: %.2f\" % accuracy(test_y, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "x3A-munyYfhO",
        "outputId": "f0ea1c77-b0bb-4308-9790-fdccded25c46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_imp = pd.Series(clf.feature_importances_, index=X.columns.values).sort_values(ascending=False)\n",
        "\n",
        "#print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3308vN_iL2X",
        "outputId": "d1cd2906-e328-4567-85b0-198f6cbb2b9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[105,  19],\n",
              "       [ 42,  36]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB1E3WeziS12",
        "outputId": "2cfd0cc6-80de-4456-91c0-cf046a3afbb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=20;, score=0.792 total time=   0.1s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=20;, score=0.820 total time=   0.1s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=20;, score=0.818 total time=   0.1s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=20;, score=0.833 total time=   0.1s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=20;, score=0.782 total time=   0.1s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=50;, score=0.829 total time=   0.3s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=50;, score=0.833 total time=   0.3s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=50;, score=0.800 total time=   0.3s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=50;, score=0.862 total time=   0.3s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=50;, score=0.793 total time=   0.3s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.6s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=100;, score=0.851 total time=   0.6s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=100;, score=0.820 total time=   0.6s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=100;, score=0.846 total time=   0.6s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=100;, score=0.807 total time=   0.6s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=200;, score=0.842 total time=   1.2s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=200;, score=0.846 total time=   1.2s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=200;, score=0.831 total time=   1.2s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=200;, score=0.853 total time=   1.2s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   1.2s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=350;, score=0.829 total time=   2.1s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=350;, score=0.846 total time=   2.1s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=350;, score=0.844 total time=   2.1s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=350;, score=0.870 total time=   2.1s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=350;, score=0.824 total time=   2.1s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=500;, score=0.820 total time=   3.0s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=500;, score=0.851 total time=   3.0s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=500;, score=0.835 total time=   3.0s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=500;, score=0.866 total time=   3.0s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=500;, score=0.822 total time=   3.0s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=20;, score=0.776 total time=   0.1s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=20;, score=0.765 total time=   0.1s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=20;, score=0.752 total time=   0.1s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=20;, score=0.796 total time=   0.1s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=20;, score=0.714 total time=   0.1s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=50;, score=0.772 total time=   0.3s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=50;, score=0.778 total time=   0.3s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=50;, score=0.752 total time=   0.3s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=50;, score=0.804 total time=   0.3s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=50;, score=0.747 total time=   0.3s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=100;, score=0.765 total time=   0.5s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=100;, score=0.767 total time=   0.5s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=100;, score=0.756 total time=   0.6s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=100;, score=0.813 total time=   0.6s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=100;, score=0.752 total time=   0.5s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=200;, score=0.781 total time=   1.1s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=200;, score=0.789 total time=   1.0s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=200;, score=0.754 total time=   1.1s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=200;, score=0.800 total time=   1.1s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=200;, score=0.738 total time=   1.1s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=350;, score=0.781 total time=   1.8s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=350;, score=0.785 total time=   1.8s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=350;, score=0.749 total time=   1.9s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=350;, score=0.796 total time=   1.9s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=350;, score=0.736 total time=   1.9s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=500;, score=0.768 total time=   2.7s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=500;, score=0.782 total time=   2.5s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=500;, score=0.756 total time=   2.6s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=500;, score=0.800 total time=   2.7s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=500;, score=0.738 total time=   2.7s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=20;, score=0.704 total time=   0.1s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=20;, score=0.690 total time=   0.1s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=20;, score=0.679 total time=   0.1s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=20;, score=0.708 total time=   0.1s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=20;, score=0.637 total time=   0.1s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=50;, score=0.704 total time=   0.2s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=50;, score=0.697 total time=   0.2s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=50;, score=0.699 total time=   0.2s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=50;, score=0.705 total time=   0.2s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=50;, score=0.684 total time=   0.2s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=100;, score=0.721 total time=   0.4s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=100;, score=0.681 total time=   0.4s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=100;, score=0.677 total time=   0.4s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=100;, score=0.723 total time=   0.4s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=100;, score=0.670 total time=   0.4s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=200;, score=0.706 total time=   0.9s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=200;, score=0.705 total time=   0.8s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=200;, score=0.681 total time=   0.9s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=200;, score=0.721 total time=   0.9s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=200;, score=0.653 total time=   0.9s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=350;, score=0.715 total time=   1.5s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=350;, score=0.690 total time=   1.5s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=350;, score=0.675 total time=   1.6s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=350;, score=0.705 total time=   1.5s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=350;, score=0.651 total time=   1.5s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=500;, score=0.708 total time=   2.2s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=500;, score=0.712 total time=   2.1s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=500;, score=0.705 total time=   2.1s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=500;, score=0.712 total time=   2.1s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=500;, score=0.664 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'min_samples_leaf': [2, 10, 30],\n",
              "                         'n_estimators': [20, 50, 100, 200, 350, 500]},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "  \n",
        "# define parameter search space\n",
        "param_grid = {'n_estimators': [20, 50, 100, 200, 350, 500],\n",
        "              'min_samples_leaf': [2, 10, 30]}\n",
        "              #'criterion': ['gini', 'entropy']} \n",
        "clf = RandomForestClassifier()\n",
        "grid = GridSearchCV(clf, param_grid, refit = True, cv=5, verbose = 3)\n",
        "  \n",
        "# fit the model for grid search\n",
        "grid.fit(train_s_X, train_s_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KygSYxqiZ1H",
        "outputId": "d795d9bc-1ba9-4f29-f12f-ef194c2b2b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_samples_leaf': 2, 'n_estimators': 350}\n",
            "RandomForestClassifier(min_samples_leaf=2, n_estimators=350)\n"
          ]
        }
      ],
      "source": [
        "# print best parameters after grid search\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how the best model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5zX6Vd8ieFd",
        "outputId": "9739a6eb-afbf-4913-de6c-da5049d28eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.70\n"
          ]
        }
      ],
      "source": [
        "grid_pred = grid.predict(test_X)\n",
        "print(\"accuracy: %.2f\" % accuracy(test_y, grid_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(test_y,grid_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A2ckJchoq08",
        "outputId": "211bbd67-8c6d-4f5b-bc19-da78d312c94e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7297297297297297"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdP6v6N_jF7u"
      },
      "source": [
        "* ## ë‹¤ë¥¸ê±°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCjf0lWzihTs",
        "outputId": "f0685c27-6d2b-44b8-d319-6156b20f669c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr 0.4849258626036556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ridge 0.48437766885204486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lasso 0.4843685861123426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elastic 0.4843685861123426\n",
            "LassoLars 0.4843685861123426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.59867311        nan 0.49198359        nan 0.59756661\n",
            "        nan 0.4930901         nan 0.59922407        nan 0.49087709\n",
            "        nan 0.59922407        nan 0.49087709        nan 0.59922407\n",
            "        nan 0.49087709        nan 0.59922407        nan 0.49087709]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression 0.4207920792079208\n",
            "SGDRegressor 0.4843329695789114\n",
            "Perceptron 0.4207920792079208\n",
            "[02:05:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "xgboost 0.4272905511431175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import linear_model as lm\n",
        "import xgboost as xgb\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "models = [('lr', lm.LinearRegression(n_jobs=-1)),\n",
        "          ('ridge', lm.Ridge()),\n",
        "          ('lasso', lm.Lasso()),\n",
        "          ('elastic', lm.ElasticNet()),\n",
        "          ('LassoLars', lm.LassoLars()),\n",
        "          ('LogisticRegression', lm.LogisticRegression()),\n",
        "          ('SGDRegressor', lm.SGDRegressor()),\n",
        "          ('Perceptron', lm.Perceptron(n_jobs=-1)),\n",
        "          ('xgboost', xgb.XGBRegressor())]\n",
        "\n",
        "\n",
        "n = 3\n",
        "params = {\n",
        "    'lr' : {\n",
        "        'fit_intercept': [True, False],\n",
        "        'normalize': [True, False],\n",
        "    },\n",
        "    'ridge': {\n",
        "        'alpha': [0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False],\n",
        "        'normalize': [True, False],\n",
        "    },\n",
        "    'lasso': {\n",
        "        'alpha': [0.1, 1.0, 10],\n",
        "        'fit_intercept': [True, False],\n",
        "        'normalize': [True, False],\n",
        "    },\n",
        "    'elastic': {\n",
        "        'alpha': [0.1, 1.0, 10],\n",
        "        'normalize': [True, False],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'LassoLars': {\n",
        "        'alpha': [0.1, 1.0, 10],\n",
        "        'normalize': [True, False],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'C': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'SGDRegressor': {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'alpha': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'Perceptron' :{\n",
        "        'penalty': ['None', 'l1', 'l2'],\n",
        "        'alpha': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False]\n",
        "    },\n",
        "    'xgboost': {\n",
        "        \"gamma\": uniform(0, 0.5).rvs(n),\n",
        "        \"max_depth\": range(2, 7), # default 3\n",
        "        \"n_estimators\": randint(100, 150).rvs(n), # default 100\n",
        "    }\n",
        "}\n",
        "\n",
        "best_model, best_mae = None, float('inf')\n",
        "for model_name, model in models:\n",
        "    param_grid = params[model_name]\n",
        "    grid = GridSearchCV(model, cv=5, n_jobs=-1, param_grid=param_grid)\n",
        "    grid = grid.fit(train_X, train_y)\n",
        "\n",
        "    model = grid.best_estimator_\n",
        "    predictions = model.predict(test_X)\n",
        "    mae = mean_absolute_error(test_y, predictions)\n",
        "\n",
        "    print(model_name, mae)\n",
        "\n",
        "    if mae < best_mae:\n",
        "        best_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GW1TY0ZjTfB",
        "outputId": "f496ea99-aebe-4131-9a5f-6a146e5c51df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBRegressor(gamma=0.4614612326594042, max_depth=5, n_estimators=136)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ZOukYejfVW",
        "outputId": "1549bcad-e2c7-44ac-ceb9-135fe0360c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11943917478156652\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(test_X)\n",
        "accuracy = best_model.score(test_X, test_y)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbp2sNMqkG4P"
      },
      "source": [
        "* ## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxFaqqFngXBJ",
        "outputId": "f10e7631-6d22-451f-8766-963b6689f6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on test dataset: 0.5396039603960396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifier = LinearSVC(C=10000, loss='hinge')\n",
        "classifier.fit(train_X, train_y)\n",
        "y_pred = classifier.predict(test_X)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(test_y, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Php9uzCgkGLa",
        "outputId": "79bf0480-0ac9-4566-af15-97729fa41e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cross-val-score: [0.43902439 0.56097561 0.525      0.5        0.625     ]\n",
            "cross-val-score.mean: 0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(classifier, test_X, test_y, cv=5) \n",
        "print('cross-val-score: {}'.format(scores))\n",
        "print('cross-val-score.mean: {}'.format(scores.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH5mzEd4lS4z",
        "outputId": "f2b99de7-aded-4b63-9da2-d25785cc045b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on test dataset: 0.594059405940594\n"
          ]
        }
      ],
      "source": [
        "classifier_w_rbf = SVC(kernel = 'rbf', random_state = 0, C=1, gamma=0.01)\n",
        "classifier_w_rbf.fit(train_X, train_y)\n",
        "y_pred = classifier_w_rbf.predict(test_X)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(test_y, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IbZga5hlWMu",
        "outputId": "a23ef4f3-cf57-4ae8-aa14-b8bd3164b336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cross-val-score: [0.58536585 0.58536585 0.575      0.575      0.575     ]\n",
            "cross-val-score.mean: 0.5791463414634146\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(classifier_w_rbf, test_X, test_y, cv=5) \n",
        "print('cross-val-score: {}'.format(scores))\n",
        "print('cross-val-score.mean: {}'.format(scores.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE0VJqFOlYRn",
        "outputId": "5af7a80d-0406-4f34-9a74-c14f50ef5240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.588 total time=   5.6s\n",
            "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.577 total time=   4.4s\n",
            "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.599 total time=   4.9s\n",
            "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.610 total time=   4.5s\n",
            "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.565 total time=   3.4s\n",
            "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.519 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.525 total time=   0.2s\n",
            "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.525 total time=   0.2s\n",
            "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.511 total time=   0.2s\n",
            "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.490 total time=   0.2s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.605 total time=   0.1s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.602 total time=   0.1s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.605 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.602 total time=   0.1s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.602 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.596 total time=   0.1s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.608 total time=   0.2s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.627 total time=   0.2s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.602 total time=   0.2s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.609 total time=   0.2s\n",
            "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.588 total time=  43.7s\n",
            "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.577 total time=  35.9s\n",
            "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.597 total time=  39.4s\n",
            "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.610 total time=  44.1s\n",
            "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.568 total time=  39.7s\n",
            "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.530 total time=   0.2s\n",
            "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.467 total time=   0.2s\n",
            "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.500 total time=   0.2s\n",
            "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.489 total time=   0.2s\n",
            "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.476 total time=   0.2s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.688 total time=   0.1s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.682 total time=   0.1s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.688 total time=   0.1s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.691 total time=   0.1s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.676 total time=   0.1s\n",
            "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.594 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.622 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.613 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.613 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.604 total time=   0.1s\n",
            "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.566 total time=   0.2s\n",
            "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.519 total time=   0.2s\n",
            "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.569 total time=   0.2s\n",
            "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.577 total time=   0.2s\n",
            "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.554 total time=   0.2s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.610 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.605 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.607 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.610 total time=   0.2s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.594 total time=   0.2s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.644 total time=   0.2s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.613 total time=   0.2s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.582 total time=   0.2s\n",
            "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.588 total time= 6.0min\n",
            "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.577 total time= 7.5min\n",
            "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.597 total time= 8.6min\n",
            "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.610 total time= 9.5min\n",
            "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.565 total time= 5.5min\n",
            "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.522 total time=   0.2s\n",
            "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.478 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.486 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.506 total time=   0.1s\n",
            "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.501 total time=   0.1s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.669 total time=   0.2s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.677 total time=   0.2s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.671 total time=   0.2s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.663 total time=   0.2s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.657 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.586 total time=   0.5s\n",
            "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.575 total time=   0.3s\n",
            "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.599 total time=   0.4s\n",
            "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.605 total time=   0.4s\n",
            "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.582 total time=   0.4s\n",
            "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.486 total time=   0.1s\n",
            "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.456 total time=   0.1s\n",
            "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.517 total time=   0.1s\n",
            "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.533 total time=   0.1s\n",
            "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.529 total time=   0.1s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.649 total time=   0.1s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.699 total time=   0.1s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.660 total time=   0.1s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.669 total time=   0.1s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.643 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.610 total time=   0.2s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.594 total time=   0.2s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.644 total time=   0.2s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.613 total time=   0.2s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.582 total time=   0.2s\n",
            "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.588 total time=64.1min\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "  \n",
        "# define parameter search space\n",
        "param_grid = {'C': [0.1, 1, 10, 100], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['rbf', 'poly', 'sigmoid']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fit the model for grid search\n",
        "grid.fit(train_X, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BOkUCd-lbIp"
      },
      "outputs": [],
      "source": [
        "# print best parameters after grid search\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how the best model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulMbkAD9ldWg"
      },
      "outputs": [],
      "source": [
        "# evaluate the model with the best parameters chosen thru tuning\n",
        "grid_pred = grid.predict(test_X)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(test_y, grid_pred)))\n",
        "print(\"recall on test dataset: {}\".format(recall_score(test_y, grid_pred, average='micro')))\n",
        "print(\"precision on test dataset: {}\".format(precision_score(test_y, grid_pred, average='micro')))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TdP6v6N_jF7u",
        "Vbp2sNMqkG4P"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}