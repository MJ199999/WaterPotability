{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ199999/WaterPotability/blob/main/WaterQuality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZP8ace0eXmw"
      },
      "outputs": [],
      "source": [
        "!pip install dataprep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZqooS6xXY4Fm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PEt-icHXbPSE"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"water_potability.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZBfc9ZxBbZUA",
        "outputId": "c4df6ba1-fa1b-4da7-9dd7-68491b7c3d2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f329c1a-d229-4acb-a73b-db5dab4862b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f329c1a-d229-4acb-a73b-db5dab4862b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f329c1a-d229-4acb-a73b-db5dab4862b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f329c1a-d229-4acb-a73b-db5dab4862b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
              "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
              "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM70ZAhVbbeB",
        "outputId": "71cd4dbb-1a36-4489-8be0-32aeba99afd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fill Na"
      ],
      "metadata": {
        "id": "dP1LrF65PCz6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wTC2YRJrbxRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ec3624-a88e-443f-a85e-bf335b9b48bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ph                 0\n",
            "Hardness           0\n",
            "Solids             0\n",
            "Chloramines        0\n",
            "Sulfate            0\n",
            "Conductivity       0\n",
            "Organic_carbon     0\n",
            "Trihalomethanes    0\n",
            "Turbidity          0\n",
            "Potability         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# data2 = data.dropna(axis=0)\n",
        "data2 = data\n",
        "data2['ph'] = data2['ph'].fillna(data2.groupby(['Potability'])['ph'].transform('mean'))\n",
        "data2['Sulfate'] = data2['Sulfate'].fillna(data2.groupby(['Potability'])['Sulfate'].transform('mean'))\n",
        "data2['Trihalomethanes'] = data2['Trihalomethanes'].fillna(data2.groupby(['Potability'])['Trihalomethanes'].transform('mean'))\n",
        "\n",
        "print(data2.isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data2.drop(['Potability'], axis=1)\n",
        "y = data2.Potability\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.1)\n",
        "train = pd.concat([train_X, train_y], axis=1)"
      ],
      "metadata": {
        "id": "fDTt810fOZul"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling"
      ],
      "metadata": {
        "id": "EKf8FBrvPHv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "train_potable = train[train['Potability']==1]\n",
        "train_notpotable = train[train['Potability']==0]\n",
        "df_minority_upsampled = resample(train_potable, replace=True, n_samples=1200)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "train_s = pd.concat([train_notpotable, df_minority_upsampled])\n",
        "train_s = shuffle(train_s)\n",
        "\n",
        "train_s_X = train_s.drop(['Potability'], axis=1)\n",
        "train_s_y =  train_s.Potability"
      ],
      "metadata": {
        "id": "g4Lh-q2LmLAx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "5DPHNpZ1nlHe",
        "outputId": "d7ca6607-1995-4a0a-b13e-e42e93a56e5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "3105  9.172625  165.687548  11319.106232     6.618853  372.554713   \n",
              "1596  8.512781  157.666918  33092.669353     6.765469  305.855570   \n",
              "2380  7.852207  169.028379  22912.189579     9.616223  332.566990   \n",
              "567   9.011589  228.919519  25208.151842     6.767010  334.564290   \n",
              "2772  8.014183  244.120098  30566.767504     7.714447  307.987458   \n",
              "...        ...         ...           ...          ...         ...   \n",
              "539   7.085378  204.923829  12556.754047     5.789008  359.951766   \n",
              "1912  7.760189  206.208834  34250.163925     7.930382  299.131598   \n",
              "1475  5.514062  212.555066  27859.748306     6.646356  286.474806   \n",
              "2663  4.556657  156.422941  14400.718629     9.461285  334.564290   \n",
              "1913  7.280560  228.539543  29690.917158     7.871025  322.269661   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "3105    420.429110       13.353259        72.974051   3.686395           0  \n",
              "1596    377.618945       13.309391        43.019427   4.026622           1  \n",
              "2380    468.445396       12.601122        80.625160   3.532438           1  \n",
              "567     380.145205       15.518323        66.303555   2.897293           0  \n",
              "2772    309.930428       22.641598        61.578461   3.417076           1  \n",
              "...            ...             ...              ...        ...         ...  \n",
              "539     610.767576       16.012643        52.442326   3.257744           0  \n",
              "1912    347.180780       19.350765        80.621872   4.590528           1  \n",
              "1475    524.547975       13.067803        99.918387   4.460363           0  \n",
              "2663    483.745716        7.897724        54.913943   4.392257           0  \n",
              "1913    392.532597       15.168189        84.370713   2.919796           1  \n",
              "\n",
              "[3007 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e3bee5-5bf9-4580-adfd-80d5a0eb1df2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3105</th>\n",
              "      <td>9.172625</td>\n",
              "      <td>165.687548</td>\n",
              "      <td>11319.106232</td>\n",
              "      <td>6.618853</td>\n",
              "      <td>372.554713</td>\n",
              "      <td>420.429110</td>\n",
              "      <td>13.353259</td>\n",
              "      <td>72.974051</td>\n",
              "      <td>3.686395</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>8.512781</td>\n",
              "      <td>157.666918</td>\n",
              "      <td>33092.669353</td>\n",
              "      <td>6.765469</td>\n",
              "      <td>305.855570</td>\n",
              "      <td>377.618945</td>\n",
              "      <td>13.309391</td>\n",
              "      <td>43.019427</td>\n",
              "      <td>4.026622</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2380</th>\n",
              "      <td>7.852207</td>\n",
              "      <td>169.028379</td>\n",
              "      <td>22912.189579</td>\n",
              "      <td>9.616223</td>\n",
              "      <td>332.566990</td>\n",
              "      <td>468.445396</td>\n",
              "      <td>12.601122</td>\n",
              "      <td>80.625160</td>\n",
              "      <td>3.532438</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>9.011589</td>\n",
              "      <td>228.919519</td>\n",
              "      <td>25208.151842</td>\n",
              "      <td>6.767010</td>\n",
              "      <td>334.564290</td>\n",
              "      <td>380.145205</td>\n",
              "      <td>15.518323</td>\n",
              "      <td>66.303555</td>\n",
              "      <td>2.897293</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2772</th>\n",
              "      <td>8.014183</td>\n",
              "      <td>244.120098</td>\n",
              "      <td>30566.767504</td>\n",
              "      <td>7.714447</td>\n",
              "      <td>307.987458</td>\n",
              "      <td>309.930428</td>\n",
              "      <td>22.641598</td>\n",
              "      <td>61.578461</td>\n",
              "      <td>3.417076</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>7.085378</td>\n",
              "      <td>204.923829</td>\n",
              "      <td>12556.754047</td>\n",
              "      <td>5.789008</td>\n",
              "      <td>359.951766</td>\n",
              "      <td>610.767576</td>\n",
              "      <td>16.012643</td>\n",
              "      <td>52.442326</td>\n",
              "      <td>3.257744</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>7.760189</td>\n",
              "      <td>206.208834</td>\n",
              "      <td>34250.163925</td>\n",
              "      <td>7.930382</td>\n",
              "      <td>299.131598</td>\n",
              "      <td>347.180780</td>\n",
              "      <td>19.350765</td>\n",
              "      <td>80.621872</td>\n",
              "      <td>4.590528</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>5.514062</td>\n",
              "      <td>212.555066</td>\n",
              "      <td>27859.748306</td>\n",
              "      <td>6.646356</td>\n",
              "      <td>286.474806</td>\n",
              "      <td>524.547975</td>\n",
              "      <td>13.067803</td>\n",
              "      <td>99.918387</td>\n",
              "      <td>4.460363</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>4.556657</td>\n",
              "      <td>156.422941</td>\n",
              "      <td>14400.718629</td>\n",
              "      <td>9.461285</td>\n",
              "      <td>334.564290</td>\n",
              "      <td>483.745716</td>\n",
              "      <td>7.897724</td>\n",
              "      <td>54.913943</td>\n",
              "      <td>4.392257</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1913</th>\n",
              "      <td>7.280560</td>\n",
              "      <td>228.539543</td>\n",
              "      <td>29690.917158</td>\n",
              "      <td>7.871025</td>\n",
              "      <td>322.269661</td>\n",
              "      <td>392.532597</td>\n",
              "      <td>15.168189</td>\n",
              "      <td>84.370713</td>\n",
              "      <td>2.919796</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3007 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e3bee5-5bf9-4580-adfd-80d5a0eb1df2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81e3bee5-5bf9-4580-adfd-80d5a0eb1df2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81e3bee5-5bf9-4580-adfd-80d5a0eb1df2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSSTpSD7gE5o"
      },
      "outputs": [],
      "source": [
        "# from dataprep.eda import create_report\n",
        "# create_report(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g2oSH3CjgFxU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "def scaler_samples(train_X,test_X):\n",
        "  scaler = StandardScaler()\n",
        "  train_X = scaler.fit_transform(train_X)\n",
        "  test_X = scaler.transform(test_X)\n",
        "\n",
        "  return train_X, test_X\n",
        "\n",
        "train_s_X, test_X = scaler_samples(train_s_X, test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2qOkVrPi9WD"
      },
      "source": [
        "* ## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWHey8eAh0MF",
        "outputId": "0a886773-4fe7-4ea5-e255-c95ab1ffaa6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', n_estimators=20)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
        "clf.fit(train_s_X, train_s_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9wC4dhkiJR0",
        "outputId": "e206fbc2-4bf7-428b-db72-07e63f4832c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.76\n"
          ]
        }
      ],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy\n",
        "y_pred = clf.predict(test_X)\n",
        "print(\"accuracy: %.2f\" % accuracy(test_y, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "x3A-munyYfhO",
        "outputId": "d2727b0f-2258-454a-b6b1-c26593dff814"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_imp = pd.Series(clf.feature_importances_, index=X.columns.values).sort_values(ascending=False)\n",
        "\n",
        "#print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3308vN_iL2X",
        "outputId": "5e33af6a-dc9a-4cb7-d860-431890caf34b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[176,  15],\n",
              "       [ 65,  72]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB1E3WeziS12",
        "outputId": "9644da44-dc45-4fc1-8929-61aa20271bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=20;, score=0.887 total time=   0.1s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=20;, score=0.864 total time=   0.1s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=20;, score=0.884 total time=   0.1s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=20;, score=0.849 total time=   0.1s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=20;, score=0.875 total time=   0.1s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=50;, score=0.889 total time=   0.4s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=50;, score=0.862 total time=   0.4s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=50;, score=0.885 total time=   0.3s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=50;, score=0.869 total time=   0.3s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=50;, score=0.865 total time=   0.4s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=100;, score=0.892 total time=   0.7s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=100;, score=0.865 total time=   0.7s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=100;, score=0.890 total time=   0.7s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=100;, score=0.872 total time=   0.7s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=100;, score=0.895 total time=   0.7s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=200;, score=0.877 total time=   1.4s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=200;, score=0.859 total time=   1.4s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=200;, score=0.895 total time=   1.4s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=200;, score=0.874 total time=   1.4s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=200;, score=0.882 total time=   1.4s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=350;, score=0.877 total time=   2.4s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=350;, score=0.872 total time=   2.3s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=350;, score=0.890 total time=   2.4s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=350;, score=0.875 total time=   2.4s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=350;, score=0.880 total time=   2.4s\n",
            "[CV 1/5] END min_samples_leaf=2, n_estimators=500;, score=0.889 total time=   3.4s\n",
            "[CV 2/5] END min_samples_leaf=2, n_estimators=500;, score=0.869 total time=   3.4s\n",
            "[CV 3/5] END min_samples_leaf=2, n_estimators=500;, score=0.892 total time=   3.3s\n",
            "[CV 4/5] END min_samples_leaf=2, n_estimators=500;, score=0.880 total time=   3.3s\n",
            "[CV 5/5] END min_samples_leaf=2, n_estimators=500;, score=0.887 total time=   3.4s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=20;, score=0.842 total time=   0.1s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=20;, score=0.804 total time=   0.1s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=20;, score=0.829 total time=   0.1s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=20;, score=0.814 total time=   0.1s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=20;, score=0.847 total time=   0.1s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=50;, score=0.850 total time=   0.3s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=50;, score=0.814 total time=   0.3s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=50;, score=0.834 total time=   0.3s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=50;, score=0.840 total time=   0.4s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=50;, score=0.824 total time=   0.4s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=100;, score=0.854 total time=   0.9s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=100;, score=0.824 total time=   0.9s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=100;, score=0.850 total time=   0.6s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=100;, score=0.832 total time=   0.6s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=100;, score=0.830 total time=   0.6s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=200;, score=0.852 total time=   1.2s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=200;, score=0.819 total time=   1.2s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=200;, score=0.839 total time=   1.2s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=200;, score=0.839 total time=   1.2s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=200;, score=0.840 total time=   1.2s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=350;, score=0.847 total time=   2.0s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=350;, score=0.817 total time=   2.0s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=350;, score=0.845 total time=   2.1s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=350;, score=0.850 total time=   2.1s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=350;, score=0.845 total time=   2.1s\n",
            "[CV 1/5] END min_samples_leaf=10, n_estimators=500;, score=0.846 total time=   3.7s\n",
            "[CV 2/5] END min_samples_leaf=10, n_estimators=500;, score=0.821 total time=   3.0s\n",
            "[CV 3/5] END min_samples_leaf=10, n_estimators=500;, score=0.842 total time=   2.9s\n",
            "[CV 4/5] END min_samples_leaf=10, n_estimators=500;, score=0.839 total time=   4.4s\n",
            "[CV 5/5] END min_samples_leaf=10, n_estimators=500;, score=0.845 total time=   3.0s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=20;, score=0.824 total time=   0.1s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=20;, score=0.784 total time=   0.1s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=20;, score=0.797 total time=   0.1s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=20;, score=0.792 total time=   0.1s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=20;, score=0.795 total time=   0.1s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=50;, score=0.817 total time=   0.3s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=50;, score=0.797 total time=   0.3s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=50;, score=0.794 total time=   0.3s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=50;, score=0.797 total time=   0.3s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=50;, score=0.790 total time=   0.3s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=100;, score=0.817 total time=   0.5s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=100;, score=0.801 total time=   0.5s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=100;, score=0.792 total time=   0.5s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=100;, score=0.802 total time=   0.5s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=100;, score=0.799 total time=   0.5s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=200;, score=0.827 total time=   1.0s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=200;, score=0.801 total time=   1.0s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=200;, score=0.804 total time=   1.0s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=200;, score=0.804 total time=   1.0s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=200;, score=0.805 total time=   1.0s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=350;, score=0.821 total time=   1.7s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=350;, score=0.792 total time=   1.7s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=350;, score=0.800 total time=   1.7s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=350;, score=0.807 total time=   1.7s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=350;, score=0.805 total time=   1.8s\n",
            "[CV 1/5] END min_samples_leaf=30, n_estimators=500;, score=0.821 total time=   2.7s\n",
            "[CV 2/5] END min_samples_leaf=30, n_estimators=500;, score=0.799 total time=   2.6s\n",
            "[CV 3/5] END min_samples_leaf=30, n_estimators=500;, score=0.795 total time=   2.6s\n",
            "[CV 4/5] END min_samples_leaf=30, n_estimators=500;, score=0.804 total time=   2.6s\n",
            "[CV 5/5] END min_samples_leaf=30, n_estimators=500;, score=0.799 total time=   2.5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'min_samples_leaf': [2, 10, 30],\n",
              "                         'n_estimators': [20, 50, 100, 200, 350, 500]},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "  \n",
        "# define parameter search space\n",
        "param_grid = {'n_estimators': [20, 50, 100, 200, 350, 500],\n",
        "              'min_samples_leaf': [2, 10, 30]}\n",
        "              #'criterion': ['gini', 'entropy']} \n",
        "clf = RandomForestClassifier()\n",
        "grid = GridSearchCV(clf, param_grid, refit = True, cv=5, verbose = 3)\n",
        "  \n",
        "# fit the model for grid search\n",
        "grid.fit(train_s_X, train_s_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KygSYxqiZ1H",
        "outputId": "bcffb3b2-efa0-413d-f319-8a7a760ca3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_samples_leaf': 2, 'n_estimators': 500}\n",
            "RandomForestClassifier(min_samples_leaf=2, n_estimators=500)\n"
          ]
        }
      ],
      "source": [
        "# print best parameters after grid search\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how the best model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5zX6Vd8ieFd",
        "outputId": "495e2992-ac72-4719-a86f-7c3527560463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.79\n"
          ]
        }
      ],
      "source": [
        "grid_pred = grid.predict(test_X)\n",
        "print(\"accuracy: %.2f\" % accuracy(test_y, grid_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(test_y,grid_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A2ckJchoq08",
        "outputId": "03a07c5b-15c8-49da-9701-92d179ced7f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9156626506024096"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "dV7WRt6snokX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca_list = list()\n",
        "feature_weight_list = list()\n",
        "\n",
        "# Fit a range of PCA models\n",
        "\n",
        "for n in range(1, 6):\n",
        "    \n",
        "    # Create and fit the model\n",
        "    PCAmod = PCA(n_components=n)\n",
        "    PCAmod.fit(train_s)\n",
        "    \n",
        "    # Store the model and variance\n",
        "    pca_list.append(pd.Series({'n':n, 'model':PCAmod,\n",
        "                               'var': PCAmod.explained_variance_ratio_.sum()}))\n",
        "    \n",
        "    # Calculate and store feature importances\n",
        "    abs_feature_values = np.abs(PCAmod.components_).sum(axis=0)\n",
        "    feature_weight_list.append(pd.DataFrame({'n':n, \n",
        "                                             'features': train_s.columns,\n",
        "                                             'values':abs_feature_values/abs_feature_values.sum()}))\n",
        "    \n",
        "pca_df = pd.concat(pca_list, axis=1).T.set_index('n')\n",
        "pca_df\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "hipU67J4noNe",
        "outputId": "6b67b775-a3de-4b2e-95de-cdef80a2ec0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 model       var\n",
              "n                               \n",
              "1  PCA(n_components=1)  0.999882\n",
              "2  PCA(n_components=2)  0.999965\n",
              "3  PCA(n_components=3)  0.999983\n",
              "4  PCA(n_components=4)  0.999996\n",
              "5  PCA(n_components=5)       1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c28ecea1-29e4-4b28-b11c-5b660257c03c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>var</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PCA(n_components=1)</td>\n",
              "      <td>0.999882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PCA(n_components=2)</td>\n",
              "      <td>0.999965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PCA(n_components=3)</td>\n",
              "      <td>0.999983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PCA(n_components=4)</td>\n",
              "      <td>0.999996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PCA(n_components=5)</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c28ecea1-29e4-4b28-b11c-5b660257c03c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c28ecea1-29e4-4b28-b11c-5b660257c03c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c28ecea1-29e4-4b28-b11c-5b660257c03c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdP6v6N_jF7u"
      },
      "source": [
        "* ## ë‹¤ë¥¸ê±°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCjf0lWzihTs",
        "outputId": "f0685c27-6d2b-44b8-d319-6156b20f669c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr 0.4849258626036556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ridge 0.48437766885204486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lasso 0.4843685861123426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elastic 0.4843685861123426\n",
            "LassoLars 0.4843685861123426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.59867311        nan 0.49198359        nan 0.59756661\n",
            "        nan 0.4930901         nan 0.59922407        nan 0.49087709\n",
            "        nan 0.59922407        nan 0.49087709        nan 0.59922407\n",
            "        nan 0.49087709        nan 0.59922407        nan 0.49087709]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression 0.4207920792079208\n",
            "SGDRegressor 0.4843329695789114\n",
            "Perceptron 0.4207920792079208\n",
            "[02:05:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "xgboost 0.4272905511431175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import linear_model as lm\n",
        "import xgboost as xgb\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "models = [('lr', lm.LinearRegression(n_jobs=-1)),\n",
        "          ('ridge', lm.Ridge()),\n",
        "          ('lasso', lm.Lasso()),\n",
        "          ('elastic', lm.ElasticNet()),\n",
        "          ('LassoLars', lm.LassoLars()),\n",
        "          ('LogisticRegression', lm.LogisticRegression()),\n",
        "          ('SGDRegressor', lm.SGDRegressor()),\n",
        "          ('Perceptron', lm.Perceptron(n_jobs=-1)),\n",
        "          ('xgboost', xgb.XGBRegressor())]\n",
        "\n",
        "\n",
        "n = 3\n",
        "params = {\n",
        "    'lr' : {\n",
        "        'fit_intercept': [True, False],\n",
        "        'normalize': [True, False],\n",
        "    },\n",
        "    'ridge': {\n",
        "        'alpha': [0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False],\n",
        "        'normalize': [True, False],\n",
        "    },\n",
        "    'lasso': {\n",
        "        'alpha': [0.1, 1.0, 10],\n",
        "        'fit_intercept': [True, False],\n",
        "        'normalize': [True, False],\n",
        "    },\n",
        "    'elastic': {\n",
        "        'alpha': [0.1, 1.0, 10],\n",
        "        'normalize': [True, False],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'LassoLars': {\n",
        "        'alpha': [0.1, 1.0, 10],\n",
        "        'normalize': [True, False],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'C': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'SGDRegressor': {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'alpha': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False],\n",
        "    },\n",
        "    'Perceptron' :{\n",
        "        'penalty': ['None', 'l1', 'l2'],\n",
        "        'alpha': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
        "        'fit_intercept': [True, False]\n",
        "    },\n",
        "    'xgboost': {\n",
        "        \"gamma\": uniform(0, 0.5).rvs(n),\n",
        "        \"max_depth\": range(2, 7), # default 3\n",
        "        \"n_estimators\": randint(100, 150).rvs(n), # default 100\n",
        "    }\n",
        "}\n",
        "\n",
        "best_model, best_mae = None, float('inf')\n",
        "for model_name, model in models:\n",
        "    param_grid = params[model_name]\n",
        "    grid = GridSearchCV(model, cv=5, n_jobs=-1, param_grid=param_grid)\n",
        "    grid = grid.fit(train_X, train_y)\n",
        "\n",
        "    model = grid.best_estimator_\n",
        "    predictions = model.predict(test_X)\n",
        "    mae = mean_absolute_error(test_y, predictions)\n",
        "\n",
        "    print(model_name, mae)\n",
        "\n",
        "    if mae < best_mae:\n",
        "        best_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GW1TY0ZjTfB",
        "outputId": "f496ea99-aebe-4131-9a5f-6a146e5c51df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBRegressor(gamma=0.4614612326594042, max_depth=5, n_estimators=136)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ZOukYejfVW",
        "outputId": "1549bcad-e2c7-44ac-ceb9-135fe0360c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11943917478156652\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(test_X)\n",
        "accuracy = best_model.score(test_X, test_y)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbp2sNMqkG4P"
      },
      "source": [
        "* ## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxFaqqFngXBJ",
        "outputId": "f10e7631-6d22-451f-8766-963b6689f6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on test dataset: 0.5396039603960396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifier = LinearSVC(C=10000, loss='hinge')\n",
        "classifier.fit(train_X, train_y)\n",
        "y_pred = classifier.predict(test_X)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(test_y, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Php9uzCgkGLa",
        "outputId": "79bf0480-0ac9-4566-af15-97729fa41e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cross-val-score: [0.43902439 0.56097561 0.525      0.5        0.625     ]\n",
            "cross-val-score.mean: 0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(classifier, test_X, test_y, cv=5) \n",
        "print('cross-val-score: {}'.format(scores))\n",
        "print('cross-val-score.mean: {}'.format(scores.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH5mzEd4lS4z",
        "outputId": "f2b99de7-aded-4b63-9da2-d25785cc045b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on test dataset: 0.594059405940594\n"
          ]
        }
      ],
      "source": [
        "classifier_w_rbf = SVC(kernel = 'rbf', random_state = 0, C=1, gamma=0.01)\n",
        "classifier_w_rbf.fit(train_X, train_y)\n",
        "y_pred = classifier_w_rbf.predict(test_X)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(test_y, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IbZga5hlWMu",
        "outputId": "a23ef4f3-cf57-4ae8-aa14-b8bd3164b336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cross-val-score: [0.58536585 0.58536585 0.575      0.575      0.575     ]\n",
            "cross-val-score.mean: 0.5791463414634146\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(classifier_w_rbf, test_X, test_y, cv=5) \n",
        "print('cross-val-score: {}'.format(scores))\n",
        "print('cross-val-score.mean: {}'.format(scores.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE0VJqFOlYRn",
        "outputId": "5af7a80d-0406-4f34-9a74-c14f50ef5240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.588 total time=   5.6s\n",
            "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.577 total time=   4.4s\n",
            "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.599 total time=   4.9s\n",
            "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.610 total time=   4.5s\n",
            "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.565 total time=   3.4s\n",
            "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.519 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.525 total time=   0.2s\n",
            "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.525 total time=   0.2s\n",
            "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.511 total time=   0.2s\n",
            "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.490 total time=   0.2s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.605 total time=   0.1s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.602 total time=   0.1s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.605 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.602 total time=   0.1s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.602 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.596 total time=   0.1s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.608 total time=   0.2s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.627 total time=   0.2s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.602 total time=   0.2s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.609 total time=   0.2s\n",
            "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.588 total time=  43.7s\n",
            "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.577 total time=  35.9s\n",
            "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.597 total time=  39.4s\n",
            "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.610 total time=  44.1s\n",
            "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.568 total time=  39.7s\n",
            "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.530 total time=   0.2s\n",
            "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.467 total time=   0.2s\n",
            "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.500 total time=   0.2s\n",
            "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.489 total time=   0.2s\n",
            "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.476 total time=   0.2s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.688 total time=   0.1s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.682 total time=   0.1s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.688 total time=   0.1s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.691 total time=   0.1s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.676 total time=   0.1s\n",
            "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.594 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.622 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.613 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.613 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.604 total time=   0.1s\n",
            "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.566 total time=   0.2s\n",
            "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.519 total time=   0.2s\n",
            "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.569 total time=   0.2s\n",
            "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.577 total time=   0.2s\n",
            "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.554 total time=   0.2s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.610 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.605 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.607 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.610 total time=   0.2s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.594 total time=   0.2s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.644 total time=   0.2s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.613 total time=   0.2s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.582 total time=   0.2s\n",
            "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.588 total time= 6.0min\n",
            "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.577 total time= 7.5min\n",
            "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.597 total time= 8.6min\n",
            "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.610 total time= 9.5min\n",
            "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.565 total time= 5.5min\n",
            "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.522 total time=   0.2s\n",
            "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.478 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.486 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.506 total time=   0.1s\n",
            "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.501 total time=   0.1s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.669 total time=   0.2s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.677 total time=   0.2s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.671 total time=   0.2s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.663 total time=   0.2s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.657 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.586 total time=   0.5s\n",
            "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.575 total time=   0.3s\n",
            "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.599 total time=   0.4s\n",
            "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.605 total time=   0.4s\n",
            "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.582 total time=   0.4s\n",
            "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.486 total time=   0.1s\n",
            "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.456 total time=   0.1s\n",
            "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.517 total time=   0.1s\n",
            "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.533 total time=   0.1s\n",
            "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.529 total time=   0.1s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.649 total time=   0.1s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.699 total time=   0.1s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.660 total time=   0.1s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.669 total time=   0.1s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.643 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.2s\n",
            "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.597 total time=   0.2s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.2s\n",
            "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.599 total time=   0.1s\n",
            "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.597 total time=   0.1s\n",
            "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.1s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.610 total time=   0.2s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.594 total time=   0.2s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.644 total time=   0.2s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.613 total time=   0.2s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.582 total time=   0.2s\n",
            "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.588 total time=64.1min\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "  \n",
        "# define parameter search space\n",
        "param_grid = {'C': [0.1, 1, 10, 100], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['rbf', 'poly', 'sigmoid']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fit the model for grid search\n",
        "grid.fit(train_X, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BOkUCd-lbIp"
      },
      "outputs": [],
      "source": [
        "# print best parameters after grid search\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how the best model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulMbkAD9ldWg"
      },
      "outputs": [],
      "source": [
        "# evaluate the model with the best parameters chosen thru tuning\n",
        "grid_pred = grid.predict(test_X)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(test_y, grid_pred)))\n",
        "print(\"recall on test dataset: {}\".format(recall_score(test_y, grid_pred, average='micro')))\n",
        "print(\"precision on test dataset: {}\".format(precision_score(test_y, grid_pred, average='micro')))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TdP6v6N_jF7u",
        "Vbp2sNMqkG4P"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}